---
student: Mengxuan Liu
tags: students
layout: blank.liquid
image: cover.png
---

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="card">
	<div class="title">Extend Human Perception Through Interactions that …… </div>
	<div class="title">connect us to ourselves, to each other, nature</div>
	<p class="text">What conponents of the real-world would you like to inherit into the virtual realm?</p>
	<p class="text">What novel facets of human perception do you wish to encounter within a virtual environment?</p>
	<p class="text">what is the one scenario you would prefer to  witness unfolding in a virtual setting.</p>
  </div>

  <div class="container">
		<div id="carousel">
			<!-- <figure data-modal-id="modal1"><img src="./image/soundEffect.gif"></figure> -->
			<figure data-modal-id="modal1">
				<video autoplay muted>
					<source src="./image/soundEffect.mp4" type="video/mp4" />
				</video>
			</figure>

			<!-- <figure data-modal-id="modal2"><img src="image/ai.gif"></figure> -->
			<figure data-modal-id="modal2">
				<video autoplay muted>
					<source src="./image/ai.mp4" type="video/mp4" />
				</video>
			</figure>
			
			<figure data-modal-id="modal3"><img src="./image/HumanBeingLoading.gif"></figure>
			<figure data-modal-id="modal4"><img src="./image/spaceClip.gif"></figure>

			<!-- <figure data-modal-id="modal5"><img src="./image/scheduleLog.gif"></figure> -->
			<figure data-modal-id="modal5">
				<video autoplay muted>
					<source src="./image/scheduleLog.mp4" type="video/mp4" />
				</video>
			</figure>
			
			<!-- <figure data-modal-id="modal6"><img src="./image/Seonsor.gif"></figure> -->
			<figure data-modal-id="modal6">
				<video autoplay muted>
					<source src="./image/Seonsor.mp4" type="video/mp4" />
				</video>
			</figure>
			
			<figure data-modal-id="modal7"><img src="./image/zine.gif"></figure>

			<!-- <figure data-modal-id="modal8"><img src="./image/harmonyLink.gif"></figure> -->
			<figure data-modal-id="modal8">
				<video autoplay muted>
					<source src="./image/harmonyLink.mp4" type="video/mp4" />
				</video>
			</figure>

			<!-- <figure data-modal-id="modal9"><img src="./image/carlaSim.gif"></figure> -->
			<figure data-modal-id="modal9">
				<video autoplay muted>
					<source src="./image/carlaSim.mp4" type="video/mp4" />
				</video>
			</figure>
		</div>
	</div>

<!-- The Modal -->
<div class="modal" id="modal1">
	<div class="modal-content">
		<!-- <p class="bio anim-typewriter">Noval Sensations</p> -->
	  <iframe src="https://woozy-electric-beechnut.glitch.me" style="width: 100%; height:100%; border: none;"></iframe>
	  <p class="modal-title">Noval Sensations</p>
	  <p class="essay">How can we simulate human sensations in the virtual world? How do we design experiences to make them feel real? These experiences might not necessarily need to be entirely lifelike. The virtual world itself provides us with playfulness and the potential to design new sensory encounters:
		<br> --Audio <br> --Motion <br> --Haptics <br> --Tastes/Flavors <br> --Smells 
	  </p>
	</div>
</div>
  
<div class="modal" id="modal2">
	<div class="modal-content">
	  <img class="img" src="./image/homeTender.gif">
	  <p class="modal-title">AI, Computer Vision, Projection Mapping</p>
	  <p class="essay">Building connections across physical and digital realms, as emphasized by the concept of digital twins, demands a profound understanding of human actions that can influence avatar behavior. In the physical world, we gather spatial information through our eyes and create a 3D representation in our minds, understanding the location of each object. Similarly, the metaverse requires the acquisition of a 3D structure in an unfamiliar environment and sensing its motion. Simultaneous Localization and Mapping (SLAM), a common computer vision technique, achieves this goal by estimating device motion and reconstructing an unknown environment.
	  </p>
	</div>
</div>
  
<div class="modal" id="modal3">
	<div class="modal-content">
	  <img class="img" src="./image/HumanBeingLoading.gif">
	  <p class="modal-title">Self Identiy</p>
	  <p class="essay">The impact of Web 3.0 and blockchain grants individuals more freedom and opportunities for growth, connection, expression, and self-assertion. With the assistance of AI and gesture tracking, we are motivated to create avatars representing ourselves. We can take on multiple roles in different groups, communities, and fields. Defining oneself will become more hybrid and sophisticated.
	  </p>
	</div>
</div>

<div class="modal" id="modal4">
	<div class="modal-content">
	  <img class="img" src="./image/spaceClip.gif">
	  <p class="modal-title">Hybrid __ __.</p>
	  <p class="essay">The ability to work from home, from a subway train, from China, or even from a cellphone has become feasible due to the explosive development of technology and our adaptability to new user habits.
		<br>The trend of people working from anywhere, under any ecosystem, and on any device has reduced the limitations of time and location. The transition from Web 2.0 to Web 3.0 grants us greater self-governance to curate our own schedules, routines, and lifestyles. The boundaries between different governing entities, countries, economies, and companies have been redefined, leading to the adoption of new laws, rules, and habits.
	  </p>
	</div>
</div>

<div class="modal" id="modal5">
	<div class="modal-content">
	  <img class="img" src="./image/scheduleLog2.gif">
	  <p class="modal-title">Pixalization</p>
	  <p class="essay">Empowered by technological tools and newfound freedom, people are inclined to self-organize, challenging conventional notions of groups and communities. Each individual becomes an ecosystem, leading to pixelated communities that embrace diversity.
	  </p>
	</div>
</div>

<div class="modal" id="modal6">
	<div class="modal-content">
	  <img class="img" src="./image/GSRdata.gif">
	  <p class="modal-title">Data Fusion</p>
	  <p class="essay">According to Statista, the total number of IoT-connected devices worldwide is projected to reach 30.9 billion by 2025, a sharp increase from the expected 13.8 billion in 2021. Our connection to the virtual world relies on data collection and exchange. An array of sensors and smart devices collect data, not only from our physical surroundings but also delving into our internal and psychological realms.
	  </p>
	</div>
</div>

<div class="modal" id="modal7">
	<div class="modal-content">
	  <img class="img" src="./image/zine.gif">
	  <p class="modal-title">Authorship</p>
	  <p class="essay">The hybrid access and creative usage of AI or any technology tool make the authorship in them much more sophisticated than the traditional way of media, like books, newspapers, journals, etc. Considering the components of a technology tool, there are at least three major groups involved in the authorship:
      <br>-- The program developer: who comes up with the concept and lays out the framework.
	  <br>-- The user: who works with the framework based on individual demands and creativity.
	  <br>--  The data contributor: who is latent and massive, feeding the program with real evidence and materials.
	  </p>
	</div>
</div>

<div class="modal" id="modal8">
	<div class="modal-content">
		<iframe width="420" height="315" src="https://www.youtube.com/embed/6slKyFjvTxE?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
		<p class="modal-title">Connections</p>
	  	<p class="essay">The autonomy gained from creating a virtual world prompts us to consider how to better connect with ourselves, each other, and nature. The virtual world shouldn't isolate us; it should enhance our connections.
	  </p>
	</div>
</div>

<div class="modal" id="modal9">
	<div class="modal-content">
	  <!-- <img class="img" src="./image/carlaSim.gif"> -->
	  <video class="img" autoplay muted>
		  <source src="./image/carlaSim.mp4" type="video/mp4" />
	  </video>
	  <p class="modal-title">Affordance</p>
	  <p class="essay">Various technological tools, such as Augmented Reality (AR), Virtual Reality (VR), Extended Reality (ER), and Mixed Reality (MR), provide different affordances. To what extent do we need to build Digital Twins of our real-world? Do we match, mimic, copy, or rebuild them?
      <br>The term "metaverse," formed by combining the prefix "meta" (implying transcending) with "universe," describes a hypothetical synthetic environment linked to the physical world. Coined in Neal Stephenson's speculative fiction "Snow Crash" in 1992, the metaverse envisions an alternate reality.	  </p>
	</div>
</div>

</body>
<script src="main.js"></script>
</html>